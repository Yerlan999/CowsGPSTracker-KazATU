{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703f346e",
   "metadata": {},
   "source": [
    "# Импортирование необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a96d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelhub import SHConfig\n",
    "from sentinelhub import SentinelHubCatalog\n",
    "\n",
    "import datetime, os, csv, math, re\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.ops import unary_union\n",
    "from fiona.drvsupport import supported_drivers\n",
    "import geopandas as gpd\n",
    "from matplotlib.path import Path\n",
    "from shapely.geometry import Polygon\n",
    "import earthpy.spatial as es\n",
    "import earthpy.plot as ep\n",
    "import numpy.ma as ma\n",
    "from scipy.stats.mstats import gmean, hmean\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sentinelhub import (\n",
    "    CRS,\n",
    "    BBox,\n",
    "    DataCollection,\n",
    "    DownloadRequest,\n",
    "    MimeType,\n",
    "    MosaickingOrder,\n",
    "    SentinelHubDownloadClient,\n",
    "    SentinelHubRequest,\n",
    "    bbox_to_dimensions,\n",
    "    filter_times\n",
    ")\n",
    "\n",
    "# The following is not a package. It is a file utils.py which should be in the same folder as this notebook.\n",
    "from utils import plot_image\n",
    "\n",
    "colors = ['tomato', 'navy', 'MediumSpringGreen', 'lightblue', 'orange', 'blue',\n",
    "          'maroon', 'purple', 'yellow', 'olive', 'brown', 'cyan']\n",
    "\n",
    "import csv, json, codecs, sys\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ad951",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7bbc57",
   "metadata": {},
   "source": [
    "# Подключение к аккаунту Sentinel Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32e4df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = os.getenv('CLIENT_ID')\n",
    "CLIENT_SECRET = os.environ.get('CLIENT_SECRET')\n",
    "\n",
    "config = SHConfig()\n",
    "\n",
    "if CLIENT_ID and CLIENT_SECRET:\n",
    "    config.sh_client_id = CLIENT_ID\n",
    "    config.sh_client_secret = CLIENT_SECRET\n",
    "\n",
    "if not config.sh_client_id or not config.sh_client_secret:\n",
    "    print(\"Warning! To use Process API, please provide the credentials (OAuth client ID and client secret).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9802a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = SentinelHubCatalog(config=config)\n",
    "# catalog.get_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4dd0a6",
   "metadata": {},
   "source": [
    "# Получение координат экспериментального пастбища "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_drivers['KML'] = 'rw'\n",
    "pasture_df = gpd.read_file('pasture.kml', driver='KML')\n",
    "\n",
    "all_zagons = []\n",
    "for zagon in range(len(pasture_df.index)):\n",
    "    all_zagons.append(pasture_df.loc[zagon].geometry)\n",
    "    \n",
    "merged_zagons = unary_union(all_zagons)\n",
    "\n",
    "gpd.GeoSeries([merged_zagons]).boundary.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9baf914",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, y_min, x_max, y_max = merged_zagons.bounds\n",
    "pasture_coords_wgs84 = (x_min, y_min, x_max, y_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9225214b",
   "metadata": {},
   "source": [
    "# Отправка запросов и получение снимков "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 10\n",
    "pasture_bbox = BBox(bbox=pasture_coords_wgs84, crs=CRS.WGS84)\n",
    "pasture_size = bbox_to_dimensions(pasture_bbox, resolution=resolution)\n",
    "\n",
    "print(f\"Image shape at {resolution} m resolution: {pasture_size} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7054a9b",
   "metadata": {},
   "source": [
    "# Составление маски пастбища"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffff58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_height, aoi_width = pasture_size[-1], pasture_size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc1872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "pasture_edges = []\n",
    "for zagon in range(len(pasture_df)-1):\n",
    "    polygon=[]\n",
    "\n",
    "    for coords in pasture_df.loc[zagon].geometry.exterior.coords:\n",
    "\n",
    "        x = int(np.interp(coords[0], [x_min, x_max], [0, aoi_width]))\n",
    "        y = int(np.interp(coords[1], [y_min, y_max], [aoi_height, 0]))\n",
    "\n",
    "        polygon.append((y, x))\n",
    "        \n",
    "    poly_path=Path(polygon)\n",
    "    x, y = np.mgrid[:aoi_height, :aoi_width]\n",
    "    coors=np.hstack((x.reshape(-1, 1), y.reshape(-1,1)))\n",
    "    \n",
    "    pasture_edges.append(Polygon(polygon))\n",
    "    \n",
    "    mask = ~poly_path.contains_points(coors)\n",
    "    masks.append(mask)\n",
    "    \n",
    "combined_mask = reduce(np.logical_and, masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d6864",
   "metadata": {},
   "source": [
    "# Маска для загона №1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masks[0].reshape(aoi_height, aoi_width))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c486b5",
   "metadata": {},
   "source": [
    "# Маска для пастбища"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(combined_mask.reshape(aoi_height, aoi_width))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bcaeb3",
   "metadata": {},
   "source": [
    "# Объявление вспомогательных функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab37e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(band):\n",
    "    band_min, band_max = (band.min(), band.max())\n",
    "    return ((band - band_min)/((band_max - band_min)))\n",
    "\n",
    "def brighten(band):\n",
    "    alpha=0.13\n",
    "    beta=0\n",
    "    return np.clip(alpha*band+beta, 0, 255)\n",
    "\n",
    "def Kcluster(matrix, n_clusters=3):\n",
    "#     scaler = MinMaxScaler(); matrix = scaler.fit_transform(matrix);\n",
    "#     scaler = StandardScaler(); matrix = scaler.fit_transform(matrix);\n",
    "\n",
    "    flattened_matrix = matrix.flatten()\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=45)\n",
    "    kmeans.fit(flattened_matrix.reshape(-1, 1))\n",
    "\n",
    "    cluster_labels = kmeans.labels_\n",
    "    result_index = cluster_labels.reshape(matrix.shape)\n",
    "    result_index = ma.masked_array(result_index, mask=combined_mask.reshape(aoi_height, aoi_width))\n",
    "\n",
    "    return ~(result_index == 0), ~(result_index == 1), ~(result_index == 2) \n",
    "\n",
    "def get_only_pasture(index):\n",
    "    only_pasture = ma.masked_array(ma.masked_array((index), mask=np.isinf((index)) | np.isnan((index))), mask=combined_mask.reshape(aoi_height, aoi_width))\n",
    "    return only_pasture\n",
    "\n",
    "def get_only_zagon(index, zagon):\n",
    "    only_pasture = ma.masked_array(ma.masked_array((index), mask=np.isinf((index)) | np.isnan((index))), mask=masks[zagon-1].reshape(aoi_height, aoi_width))\n",
    "    return only_pasture\n",
    "\n",
    "def mean(index):\n",
    "    return float(index.mean())\n",
    "\n",
    "def median(index):\n",
    "    return float(ma.median(index))\n",
    "\n",
    "\n",
    "def show_real_pasture():\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    for zagon in range(len(pasture_df)-1):\n",
    "        ax.plot(pasture_edges[zagon].exterior.xy[1], pasture_edges[zagon].exterior.xy[0])\n",
    "    ep.plot_rgb(np.stack([RED, GREEN, BLUE]), ax=ax, title=general_info, figsize=(12, 6))\n",
    "    plt.show()    \n",
    "\n",
    "    \n",
    "def show_pasture_index(test_meet, lower_bound, upper_bound, show_hists=True, save_excel=False):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    for zagon in range(len(pasture_df)-1):\n",
    "\n",
    "        ax.plot(pasture_edges[zagon].exterior.xy[1], pasture_edges[zagon].exterior.xy[0])\n",
    "\n",
    "    header = input_text\n",
    "    precision = 4\n",
    "    # print(f\"Макс: {round(float(test_meet.max()),precision)} || Мин: {round(float(test_meet.min()),precision)} || Сред: {round(float(test_meet.mean()),precision)} || Сумм: {round(float(test_meet.sum()),precision)}\")\n",
    "    ep.plot_bands(test_meet, title=f\"{header} {general_info}\", ax=ax, cmap=\"bwr\", cols=1, vmin=lower_bound, vmax=upper_bound, figsize=(10, 14))\n",
    "    plt.show()\n",
    "\n",
    "    test_index_masked_array = []\n",
    "    for i, mask in enumerate(masks):\n",
    "        mx = ma.masked_array(test_meet, mask=mask.reshape(aoi_height, aoi_width))\n",
    "        test_index_masked_array.append(mx)\n",
    "\n",
    "    summary_data = []\n",
    "    for i, zagon in enumerate(test_index_masked_array):\n",
    "        summary_data.append([f\"№{i+1}\", round(zagon.sum(),precision), round(zagon.mean(),precision), round(ma.median(zagon),precision), round(zagon.max(),precision), round(zagon.min(),precision)])\n",
    "\n",
    "\n",
    "    styles = [\n",
    "        {'selector': '',\n",
    "         'props': [('border', '2px solid #000'), ('border-collapse', 'collapse')]},\n",
    "        {'selector': 'th',\n",
    "         'props': [('border', '2px solid #000')]},\n",
    "        {'selector': 'td',\n",
    "         'props': [('border', '1px solid #000'), ('padding', '5px')]}\n",
    "    ]\n",
    "\n",
    "    summary_df = pd.DataFrame(data = summary_data, columns=[\"Загон\", \"Сумма\", \"Cреднаяя\", \"Медианная\", \"Макс\", \"Мин\"])\n",
    "    sum_row = pd.DataFrame({'Загон': [\"Пастбище\"], 'Сумма': [summary_df['Сумма'].sum()], 'Cреднаяя': [round(float(test_meet.mean()),precision)], 'Медианная': [round(float(ma.median(test_meet)),precision)], 'Макс': [summary_df['Макс'].max()], 'Мин': [summary_df['Мин'].min()]}, index=[len(summary_df.index)])\n",
    "    summary_df = pd.concat([summary_df, sum_row])\n",
    "    if save_excel:\n",
    "        summary_df.to_excel(f\"Summary_{date_chosen}_{data_collection.processing_level}.xlsx\", index=None)\n",
    "    styled_df = summary_df.style.set_table_styles(styles)\n",
    "    styled_df.hide(axis=\"index\")\n",
    "    \n",
    "    display(styled_df)\n",
    "\n",
    "    if show_hists:\n",
    "        for i, zagon in enumerate(test_index_masked_array):\n",
    "            ep.hist(zagon, colors = colors[i], title=f'{header} || Загон-{i+1} {general_info}', cols=4, alpha=0.5,\n",
    "            figsize = (10, 6))    \n",
    "            plt.axvline(test_index_masked_array[i].mean(), color='b', linestyle='dashed', linewidth=2)\n",
    "            plt.axvline(ma.median(test_index_masked_array[i]), color='r', linestyle='dashed', linewidth=2)\n",
    "            has_negative_or_zero = test_index_masked_array[i] <= 0\n",
    "            if not has_negative_or_zero.sum():\n",
    "                plt.axvline(hmean(test_index_masked_array[i].reshape(aoi_width * aoi_height)), color='g', linestyle='dashed', linewidth=2)\n",
    "                plt.axvline(gmean(test_index_masked_array[i].reshape(aoi_width * aoi_height)), color='y', linestyle='dashed', linewidth=2)\n",
    "                plt.legend([f\"Средняя: {test_index_masked_array[i].mean()}\",f\"Медианная: {ma.median(test_index_masked_array[i])}\",f\"Гармоническая: {hmean(test_index_masked_array[i].reshape(aoi_width * aoi_height))}\",f\"Геометрическая: {gmean(test_index_masked_array[i].reshape(aoi_width * aoi_height))}\"], title=f'Сумма: {round(zagon.sum(),precision)}')\n",
    "            else:\n",
    "                plt.legend([f\"Средняя: {ma.mean(test_index_masked_array[i])}\",f\"Медианная: {ma.median(test_index_masked_array[i])}\"], title=f'Сумма: {round(zagon.sum(),precision)}')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "def get_all_bands(by_pasture=True):\n",
    "    global ULTRA_BLUE, BLUE, GREEN, RED, RED_EDGE1, RED_EDGE2, RED_EDGE3, NIR, N_NIR, WV, SWIR_C, SWIR2, SWIR3, SAA, SZA, VAM, VZM\n",
    "    \n",
    "    if by_pasture:\n",
    "        # Нормализированные по пастбищу\n",
    "        ULTRA_BLUE = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B01\"]])))\n",
    "\n",
    "        BLUE = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B02\"]])))\n",
    "        GREEN = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B03\"]])))\n",
    "        RED = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B04\"]])))\n",
    "\n",
    "        RED_EDGE1 = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B05\"]])))\n",
    "        RED_EDGE2 = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B06\"]])))\n",
    "        RED_EDGE3 = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B07\"]])))\n",
    "\n",
    "        NIR = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B08\"]])))\n",
    "        N_NIR = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B8A\"]])))\n",
    "        WV = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B09\"]])))\n",
    "        if \"B10\" in bands_dict:\n",
    "            SWIR_C = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B10\"]])))\n",
    "        SWIR2 = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B11\"]])))\n",
    "        SWIR3 = normalize(brighten(get_only_pasture(all_bands_data[image_date][:, :, bands_dict[\"B12\"]])))\n",
    "    else:\n",
    "        # НЕ Нормализированные по пастбищу\n",
    "        ULTRA_BLUE = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B01\"]])))\n",
    "\n",
    "        BLUE = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B02\"]])))\n",
    "        GREEN = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B03\"]])))\n",
    "        RED = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B04\"]])))\n",
    "\n",
    "        RED_EDGE1 = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B05\"]])))\n",
    "        RED_EDGE2 = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B06\"]])))\n",
    "        RED_EDGE3 = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B07\"]])))\n",
    "\n",
    "        NIR = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B08\"]])))\n",
    "        N_NIR = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B8A\"]])))\n",
    "        WV = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B09\"]])))\n",
    "        if \"B10\" in bands_dict:\n",
    "            SWIR_C = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B10\"]])))\n",
    "        SWIR2 = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B11\"]])))\n",
    "        SWIR3 = get_only_pasture(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B12\"]])))\n",
    "\n",
    "    SAA = (aux_data[image_date][:, :, aux_data_dict[\"sunAzimuthAngles\"]]).mean()\n",
    "    SZA = (aux_data[image_date][:, :, aux_data_dict[\"sunZenithAngles\"]]).mean()\n",
    "    VAM = (aux_data[image_date][:, :, aux_data_dict[\"viewAzimuthMean\"]]).mean()\n",
    "    VZM = (aux_data[image_date][:, :, aux_data_dict[\"viewZenithMean\"]]).mean()\n",
    "\n",
    "bands_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0130120",
   "metadata": {},
   "source": [
    "# Анализ погодных параметров и каналов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a69506",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv(\"train_data.csv\")\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e511f",
   "metadata": {},
   "source": [
    "# Дополнительная вспомогательная функция для сбора данных ДЗЗ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3192aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_data(date_chosen, zagon, greenmass, collection, by_pasture=True):\n",
    "    global bands_dict\n",
    "    \n",
    "    if collection == \"L1C\":\n",
    "        data_collection = DataCollection.SENTINEL2_L1C\n",
    "    elif collection == \"L2A\":\n",
    "        data_collection = DataCollection.SENTINEL2_L2A\n",
    "\n",
    "    bands_dict = dict([(band.name, i) for i, band in enumerate(data_collection.bands)])\n",
    "    aux_data_dict = dict([(band, i) for i, band in enumerate([\"sunZenithAngles\",\"sunAzimuthAngles\",\"viewZenithMean\",\"viewAzimuthMean\"])])\n",
    "\n",
    "    evalscript_all_bands = \"\"\"\n",
    "        //VERSION=3\n",
    "        function setup() {{\n",
    "            return {{\n",
    "                input: [{{\n",
    "                    bands: [{BANDS}],\n",
    "                    units: \"DN\"\n",
    "                }}],\n",
    "                output: {{\n",
    "                    bands: {COUNT},\n",
    "                    sampleType: \"FLOAT32\"\n",
    "                }}\n",
    "            }};\n",
    "        }}\n",
    "\n",
    "        function evaluatePixel(sample) {{\n",
    "            return [{SAMPLE}];\n",
    "        }}\n",
    "    \"\"\"\n",
    "    template1 = \"\"; template2 = \"\"\n",
    "    for band in bands_dict.keys():\n",
    "        template1 += f'\"{band}\", ';\n",
    "        template2 += f'sample.{band}, ';\n",
    "    settings = {\"BANDS\": template1, \"SAMPLE\": template2, \"COUNT\": str(len(bands_dict))}\n",
    "    evalscript_all_bands = evalscript_all_bands.format(**settings)\n",
    "\n",
    "\n",
    "    evalscript_aux_data = \"\"\"\n",
    "        //VERSION=3\n",
    "\n",
    "        function setup() {{\n",
    "            return {{\n",
    "                input: [{{\n",
    "                    bands: [{BANDS}],\n",
    "                    units: \"DEGREES\"\n",
    "                }}],\n",
    "                output: {{\n",
    "                    bands: {COUNT},\n",
    "                    sampleType: \"FLOAT32\"\n",
    "                }}\n",
    "            }};\n",
    "        }}\n",
    "\n",
    "        function evaluatePixel(sample) {{\n",
    "            return [{SAMPLE}];\n",
    "        }}\n",
    "    \"\"\"\n",
    "    template1 = \"\"; template2 = \"\"\n",
    "    for band in aux_data_dict.keys():\n",
    "        template1 += f'\"{band}\", ';\n",
    "        template2 += f'sample.{band}, ';\n",
    "    settings = {\"BANDS\": template1, \"SAMPLE\": template2, \"COUNT\": str(len(aux_data_dict))}\n",
    "    evalscript_aux_data = evalscript_aux_data.format(**settings)\n",
    "\n",
    "\n",
    "    time_interval = date_chosen, date_chosen\n",
    "\n",
    "    search_iterator = catalog.search(\n",
    "        data_collection,\n",
    "        bbox=pasture_bbox,\n",
    "        time=time_interval,\n",
    "        filter=\"eo:cloud_cover <= 100\",\n",
    "        fields={\"include\": [\"id\", \"properties.datetime\", \"properties.eo:cloud_cover\"], \"exclude\": []},\n",
    "    )\n",
    "\n",
    "    results = list(search_iterator)\n",
    "\n",
    "    time_difference = datetime.timedelta(hours=1)\n",
    "    all_timestamps = search_iterator.get_timestamps()\n",
    "    unique_acquisitions = filter_times(all_timestamps, time_difference)\n",
    "\n",
    "\n",
    "    all_bands_process_requests = []\n",
    "\n",
    "    for timestamp in unique_acquisitions:\n",
    "        request = SentinelHubRequest(\n",
    "            evalscript=evalscript_all_bands,\n",
    "            input_data=[\n",
    "                SentinelHubRequest.input_data(\n",
    "                    data_collection=data_collection,\n",
    "                    time_interval=(timestamp - time_difference, timestamp + time_difference),\n",
    "                )\n",
    "            ],\n",
    "            responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n",
    "            bbox=pasture_bbox,\n",
    "            size=pasture_size,\n",
    "            config=config,\n",
    "        )\n",
    "        all_bands_process_requests.append(request)\n",
    "\n",
    "    aux_data_process_requests = []\n",
    "\n",
    "    for timestamp in unique_acquisitions:\n",
    "        request = SentinelHubRequest(\n",
    "            evalscript=evalscript_aux_data,\n",
    "            input_data=[\n",
    "                SentinelHubRequest.input_data(\n",
    "                    data_collection=data_collection,\n",
    "                    time_interval=(timestamp - time_difference, timestamp + time_difference),\n",
    "                )\n",
    "            ],\n",
    "            responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n",
    "            bbox=pasture_bbox,\n",
    "            size=pasture_size,\n",
    "            config=config,\n",
    "        )\n",
    "        aux_data_process_requests.append(request)\n",
    "\n",
    "    client = SentinelHubDownloadClient(config=config)\n",
    "    all_bands_download_requests = [request.download_list[0] for request in all_bands_process_requests]\n",
    "    all_bands_data = client.download(all_bands_download_requests)\n",
    "\n",
    "    client = SentinelHubDownloadClient(config=config)\n",
    "    aux_data_download_requests = [request.download_list[0] for request in aux_data_process_requests]\n",
    "    aux_data = client.download(aux_data_download_requests)\n",
    "\n",
    "    white_noise_threshold = 255 # Значение [0-255]\n",
    "    white_noise_count = 12246 # Количество 157*78=[0-12246]\n",
    "\n",
    "    clear_date_dict = []\n",
    "    for i, (image, timestamp) in enumerate(zip(all_bands_data, unique_acquisitions)):\n",
    "\n",
    "        data = image.astype(np.float64) / image.max()\n",
    "        data = 255 * data\n",
    "        image = data.astype(np.uint8)\n",
    "\n",
    "        mx1 = ma.masked_array(image[:,:,bands_dict[\"B02\"]], mask=combined_mask.reshape(aoi_height, aoi_width))\n",
    "        mx2 = ma.masked_array(image[:,:,bands_dict[\"B03\"]], mask=combined_mask.reshape(aoi_height, aoi_width))\n",
    "        mx3 = ma.masked_array(image[:,:,bands_dict[\"B04\"]], mask=combined_mask.reshape(aoi_height, aoi_width))\n",
    "        comb = mx1&mx2&mx3\n",
    "        white_image = comb >= white_noise_threshold\n",
    "        if white_image.sum() <= white_noise_count:\n",
    "            clear_date_dict.append((str(timestamp.date().isoformat()), i))\n",
    "\n",
    "    clear_date_dict = dict(clear_date_dict)\n",
    "    image_date = clear_date_dict[date_chosen]\n",
    "\n",
    "    SAA = (aux_data[image_date][:, :, aux_data_dict[\"sunAzimuthAngles\"]]).mean()\n",
    "    SZA = (aux_data[image_date][:, :, aux_data_dict[\"sunZenithAngles\"]]).mean()\n",
    "    VAM = (aux_data[image_date][:, :, aux_data_dict[\"viewAzimuthMean\"]]).mean()\n",
    "    VZM = (aux_data[image_date][:, :, aux_data_dict[\"viewZenithMean\"]]).mean()\n",
    "\n",
    "    if by_pasture:\n",
    "        # Нормализированные по пастбищу\n",
    "        ULTRA_BLUE = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B01\"]],zagon)))\n",
    "\n",
    "        BLUE = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B02\"]],zagon)))\n",
    "        GREEN = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B03\"]],zagon)))\n",
    "        RED = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B04\"]],zagon)))\n",
    "\n",
    "        RED_EDGE1 = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B05\"]],zagon)))\n",
    "        RED_EDGE2 = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B06\"]],zagon)))\n",
    "        RED_EDGE3 = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B07\"]],zagon)))\n",
    "\n",
    "        NIR = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B08\"]],zagon)))\n",
    "        N_NIR = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B8A\"]],zagon)))\n",
    "        WV = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B09\"]],zagon)))\n",
    "        if \"B10\" in bands_dict:\n",
    "            SWIR_C = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B10\"]],zagon)))\n",
    "        SWIR2 = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B11\"]],zagon)))\n",
    "        SWIR3 = normalize(brighten(get_only_zagon(all_bands_data[image_date][:, :, bands_dict[\"B12\"]],zagon)))\n",
    "\n",
    "    else:\n",
    "        # НЕ Нормализированные по пастбищу\n",
    "        ULTRA_BLUE = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B01\"]])),zagon)\n",
    "\n",
    "        BLUE = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B02\"]])),zagon)\n",
    "        GREEN = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B03\"]])),zagon)\n",
    "        RED = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B04\"]])),zagon)\n",
    "\n",
    "        RED_EDGE1 = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B05\"]])),zagon)\n",
    "        RED_EDGE2 = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B06\"]])),zagon)\n",
    "        RED_EDGE3 = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B07\"]])),zagon)\n",
    "\n",
    "        NIR = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B08\"]])),zagon)\n",
    "        N_NIR = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B8A\"]])),zagon)\n",
    "        WV = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B09\"]])),zagon)\n",
    "        if \"B10\" in bands_dict:\n",
    "            SWIR_C = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B10\"]])),zagon)\n",
    "        SWIR2 = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B11\"]])),zagon)\n",
    "        SWIR3 = get_only_zagon(normalize(brighten(all_bands_data[image_date][:, :, bands_dict[\"B12\"]])),zagon)\n",
    "\n",
    "    print(f\"Успешно получены каналы для даты: {date_chosen} и загона №{zagon}\")\n",
    "    if \"B10\" in bands_dict:\n",
    "        return [\"time\", \"zagon\", \"greenmass\"] + list(bands_dict.keys()) + list(aux_data_dict.keys()), [date_chosen, zagon, greenmass, ULTRA_BLUE, BLUE, GREEN, RED, RED_EDGE1, RED_EDGE2, RED_EDGE3, NIR, N_NIR, WV, SWIR_C, SWIR2, SWIR3, SZA, SAA, VZM, VAM]\n",
    "    else:\n",
    "        return [\"time\", \"zagon\", \"greenmass\"] + list(bands_dict.keys()) + list(aux_data_dict.keys()), [date_chosen, zagon, greenmass, ULTRA_BLUE, BLUE, GREEN, RED, RED_EDGE1, RED_EDGE2, RED_EDGE3, NIR, N_NIR, WV, SWIR2, SWIR3, SZA, SAA, VZM, VAM]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827192b",
   "metadata": {},
   "source": [
    "# Получение данных ДЗЗ по доступным датам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f72aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations, combinations, product\n",
    "from math import factorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b129f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_index = eval(formula_text)\n",
    "\n",
    "# test_thresh = test_index.min() \n",
    "# #     test_thresh = (test_index.max() + test_index.min())/2\n",
    "# # test_thresh = 0\n",
    "\n",
    "# test_filter = test_index >= test_thresh; test_mask = ~test_filter\n",
    "# test_meet = ma.masked_array(test_index, mask=test_mask)\n",
    "\n",
    "# # lower_bound = -1;  upper_bound = 1\n",
    "# lower_bound = test_meet.min(); upper_bound = test_meet.max()    \n",
    "# mask = (test_meet < lower_bound) | (test_meet > upper_bound)\n",
    "\n",
    "# test_meet = ma.masked_array(test_meet, mask=mask)\n",
    "\n",
    "# ep.plot_bands(test_meet, title=f\"Канал для даты: {date_chosen} и загона №{zagon}\", cmap=\"viridis\")\n",
    "\n",
    "# #     test_meet = test_meet.mean()\n",
    "# #     test_meet = ma.median(test_meet)\n",
    "# test_meet = test_meet.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba072f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e265753",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_form = []\n",
    "for index in training_df.index:\n",
    "    data_lables, data_list = get_date_data(training_df.loc[index, 'time'], training_df.loc[index, 'zagon'], training_df.loc[index, 'greenmass'], \"L2A\", by_pasture=False)\n",
    "    sample_form.append(data_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade5742",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_df = pd.DataFrame(sample_form, columns=data_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc9f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_types = {\n",
    "    \"term1\": 1,\n",
    "    \n",
    "    \"term1+term2\": 2,\n",
    "    \"term1-term2\": 2,\n",
    "    \n",
    "    \"term1/term2\": 2,\n",
    "    \"term1*term2\": 2,\n",
    "    \n",
    "    \"term1/term2 * term3\": 3,\n",
    "    \n",
    "    \"(term1-term2)/(term1+term2)\": 2,\n",
    "    \n",
    "    \"(term1+term2)/(term3+term4)\": 4,\n",
    "    \n",
    "    \"(term1+term2)/(term3-term4)\": 4,\n",
    "    \"(term1-term2)/(term3-term4)\": 4,\n",
    "    \n",
    "    \"(term1-term2)/(term3-term4) * term5\": 5,\n",
    "}\n",
    "methods = [\"mean\", \"median\", \"harmonic\", \"geometric\", \"max\", \"min\", \"sum\"]\n",
    "\n",
    "\n",
    "combination_results = dict()\n",
    "for formula_type, members in formula_types.items():\n",
    "    combination_results[formula_type] = dict()\n",
    "    for method in methods:\n",
    "        combination_results[formula_type][method] = dict()\n",
    "        for bands_combination in permutations(list(bands_dict.keys()), members):\n",
    "            combination_results[formula_type][method][bands_combination] = dict()\n",
    "            calculated_GM = []\n",
    "            for sample in indices_df.index:\n",
    "                replacer_terms = dict()\n",
    "                \n",
    "                for term in range(members):\n",
    "                    exec(f'term{term+1} = indices_df.iloc[{sample}][\"{bands_combination[term]}\"]')\n",
    "            \n",
    "                formula = eval(formula_type)\n",
    "                final_value = np.nan\n",
    "                \n",
    "                if method == \"mean\":\n",
    "                    final_value = formula.mean()\n",
    "                elif method == \"median\":\n",
    "                    final_value = ma.median(formula)\n",
    "                elif method == \"harmonic\":\n",
    "                    try:\n",
    "                        final_value = hmean(formula.reshape(formula.shape[1] * formula.shape[0]))\n",
    "                    except ValueError:\n",
    "                        final_value = np.nan\n",
    "                elif method == \"geometric\":\n",
    "                    try:\n",
    "                        final_value = gmean(formula.reshape(formula.shape[1] * formula.shape[0]))\n",
    "                    except ValueError:\n",
    "                        final_value = np.nan\n",
    "                elif method == \"max\":\n",
    "                    final_value = formula.max()\n",
    "                elif method == \"min\":\n",
    "                    final_value = formula.min()\n",
    "                else:\n",
    "                    final_value = formula.sum()\n",
    "                \n",
    "                \n",
    "                \n",
    "                calculated_GM.append(final_value)\n",
    "\n",
    "            combination_results[formula_type][method][bands_combination] = np.corrcoef(calculated_GM, list(indices_df[\"greenmass\"]))[0, 1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the data\n",
    "formula_list = []\n",
    "method_list = []\n",
    "upper_highest_list = []\n",
    "lower_highest_list = []\n",
    "\n",
    "for formula_type, members in formula_types.items():\n",
    "    for method in methods:\n",
    "        upper_highest = list(sorted(combination_results[formula_type][method].items(), key=lambda item: item[1]))[0]\n",
    "        lower_highest = list(sorted(combination_results[formula_type][method].items(), key=lambda item: item[1]))[-1]\n",
    "\n",
    "        # Round the float values to a certain number of decimal places (e.g., 2)\n",
    "        upper_highest = (upper_highest[0], round(upper_highest[1], 4))\n",
    "        lower_highest = (lower_highest[0], round(lower_highest[1], 4))\n",
    "        \n",
    "        formula_list.append(formula_type)\n",
    "        method_list.append(method)\n",
    "        upper_highest_list.append(upper_highest)\n",
    "        lower_highest_list.append(lower_highest)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Formula Type': formula_list,\n",
    "    'Method': method_list,\n",
    "    'Upper Highest': upper_highest_list,\n",
    "    'Lower Highest': lower_highest_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    print(i, df.iloc[i][\"Upper Highest\"], df.iloc[i][\"Lower Highest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to show all rows and columns without truncation\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe941a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c0ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset display options to default (optional)\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"FormulasComparision.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c51682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2482397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination_results = dict()\n",
    "# for bands_combination in permutations(list(bands_dict.keys()), 4):\n",
    "#     calculated_GM = []\n",
    "#     for sample in indices_df.index:\n",
    "#         term1 = indices_df.iloc[sample][f\"{bands_combination[0]}\"]\n",
    "#         term2 = indices_df.iloc[sample][f\"{bands_combination[1]}\"]\n",
    "#         term3 = indices_df.iloc[sample][f\"{bands_combination[2]}\"]\n",
    "#         term4 = indices_df.iloc[sample][f\"{bands_combination[3]}\"]\n",
    "\n",
    "#         formula = (term1+term2)/(term3+term4)\n",
    "#         final_value = ma.median(formula)\n",
    "#         calculated_GM.append(final_value)\n",
    "\n",
    "#     combination_results[bands_combination] = np.corrcoef(calculated_GM, list(indices_df[\"greenmass\"]))[0, 1]\n",
    "\n",
    "# print(\"Всего комбинации: \", len(combination_results))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e468f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(sorted(combination_results.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7b5812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(sorted(combination_results.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f163e",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8edff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e9472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d25dacf",
   "metadata": {},
   "source": [
    "# Анализ перед обучением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the correlation matrix\n",
    "# correlation_matrix = input_df.corr()\n",
    "\n",
    "# # Create a heatmap using seaborn\n",
    "# plt.figure(figsize=(18, 16))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='bwr', fmt=\".2f\", linewidths=.5)\n",
    "\n",
    "# plt.axvline(x=18, color='black', linewidth=2)\n",
    "# plt.axvline(x=19, color='black', linewidth=2)\n",
    "\n",
    "# plt.axhline(y=13, color='black', linewidth=2)\n",
    "# plt.axhline(y=14, color='black', linewidth=2)\n",
    "\n",
    "# plt.title(\"Correlation Matrix Plot\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e64211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(len(input_df.index)), input_df[\"index\"]/100, label='Прогноз со спутника')\n",
    "# plt.plot(range(len(input_df.index)), input_df[\"greenmass\"], label='Наземные данные')\n",
    "# # plt.plot(range(len(input_df.index)), input_df[\"sunZenithAngles\"], label='SZA')\n",
    "\n",
    "# plt.title('Урожайность реальная vs Урожайность прогноз')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49211e3",
   "metadata": {},
   "source": [
    "# Генетический алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433efff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def masked_matrix_median(masked_matrix):\n",
    "#     return ma.median(masked_matrix)\n",
    "\n",
    "# bands_matrices = indices_df.iloc[:,3:15]\n",
    "# green_mass = indices_df.iloc[:,2:3]\n",
    "\n",
    "# bands_matrices_median = bands_matrices.applymap(masked_matrix_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f142fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import permutations\n",
    "# import numpy as np\n",
    "# from deap import base, creator, tools, algorithms\n",
    "# import pandas as pd\n",
    "# import numpy.ma as ma\n",
    "\n",
    "# # Set up DEAP framework for Genetic Algorithm\n",
    "# creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "# creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# toolbox = base.Toolbox()\n",
    "# toolbox.register(\"indices\", np.random.permutation, len(bands_dict))\n",
    "# toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.indices)\n",
    "# toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# def evaluate(individual):\n",
    "#     bands_combination = [list(bands_dict.keys())[i] for i in individual[:4]]\n",
    "    \n",
    "#     calculated_GM = []\n",
    "#     for sample in indices_df.index:\n",
    "#         terms = [indices_df.iloc[sample][f\"{band}\"] for band in bands_combination]\n",
    "#         formula = (terms[0] + terms[1]) / (terms[2] + terms[3])\n",
    "#         final_value = ma.median(formula)\n",
    "#         calculated_GM.append(final_value)\n",
    "    \n",
    "#     correlation = np.corrcoef(calculated_GM, list(indices_df[\"greenmass\"]))[0, 1]\n",
    "#     return correlation,\n",
    "\n",
    "# toolbox.register(\"evaluate\", evaluate)\n",
    "# toolbox.register(\"mate\", tools.cxOrdered)\n",
    "# toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.2)\n",
    "# toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Assuming you have initialized your indices_df dataframe\n",
    "\n",
    "#     # Set random seed for reproducibility\n",
    "# #     np.random.seed(42)\n",
    "\n",
    "#     # Create an initial population\n",
    "#     population_size = 10\n",
    "#     population = toolbox.population(n=population_size)\n",
    "\n",
    "#     # Evaluate the entire population\n",
    "#     fitnesses = list(map(toolbox.evaluate, population))\n",
    "#     for ind, fit in zip(population, fitnesses):\n",
    "#         ind.fitness.values = fit\n",
    "\n",
    "#     # Crossover and mutation probabilities\n",
    "#     cxpb, mutpb = 0.7, 0.2\n",
    "\n",
    "#     # Number of generations\n",
    "#     ngen = 5\n",
    "\n",
    "#     # Statistics to collect during the optimization\n",
    "#     stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "#     stats.register(\"max\", np.max)\n",
    "\n",
    "#     # Run the Genetic Algorithm\n",
    "#     algorithms.eaMuPlusLambda(population, toolbox, mu=population_size, lambda_=2*population_size,\n",
    "#                               cxpb=cxpb, mutpb=mutpb, ngen=ngen, stats=stats, halloffame=None, verbose=True)\n",
    "\n",
    "#     # Get the best individual and its fitness value\n",
    "#     best_individual = tools.selBest(population, k=1)[0]\n",
    "#     best_combination = [list(bands_dict.keys())[int(i)] for i in best_individual[:4]]\n",
    "#     best_fitness = best_individual.fitness.values[0]\n",
    "\n",
    "#     print(\"Лучшая комбинация каналов:\", best_combination)\n",
    "#     print(\"Лучшая корреляция:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ed26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af730179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6bc0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc58428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda825c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination_results = dict()\n",
    "# for bands_combination in permutations(list(bands_dict.keys()), 4):\n",
    "#     calculated_GM = []\n",
    "#     for sample in indices_df.index:\n",
    "#         term1 = indices_df.iloc[sample][f\"{bands_combination[0]}\"]\n",
    "#         term2 = indices_df.iloc[sample][f\"{bands_combination[1]}\"]\n",
    "#         term3 = indices_df.iloc[sample][f\"{bands_combination[2]}\"]\n",
    "#         term4 = indices_df.iloc[sample][f\"{bands_combination[3]}\"]\n",
    "\n",
    "#         formula = (term1+term2)/(term3+term4)\n",
    "#         final_value = ma.median(formula)\n",
    "#         calculated_GM.append(final_value)\n",
    "\n",
    "#     combination_results[bands_combination] = np.corrcoef(calculated_GM, list(indices_df[\"greenmass\"]))[0, 1]\n",
    "\n",
    "# Clarification of the code above:    \n",
    "# 1) \"indices_df\" dataframe has 17 rows and 13 columns, namely: \"greenmass\" and 12 bands (\"B01\", \"B02\" ... and so on)\n",
    "# 2) each band is a masked matrix of size (175, 78)\n",
    "# 3) This code searches for the best possible combination of 4 bands out of 12 bands.\n",
    "# 4) Correlation with \"greenmass\" column is assessed\n",
    "# 5) bands_dict dictionary's keys contain bands' names as strings (\"B01\", \"B02\" ... and so on)\n",
    "\n",
    "# Actually, it does fine. I was able to find a set of bands with a 90% correlation. So, my question is what kind of Machine Learning or Optimization Algorithm can do the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ccab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# band = \"B12\"\n",
    "# cmap = \"viridis\"\n",
    "# for i in indices_df.index:\n",
    "#     ep.plot_bands(indices_df.iloc[i][band], title=f\"{indices_df.iloc[i]['time']} || {indices_df.iloc[i]['zagon']}\", cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b3690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [\n",
    "    \"(NIR - RED) / (NIR + RED)\",\n",
    "    \"2.5 * (NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1)\",\n",
    "    \"(NIR - RED) / (NIR + RED + 0.5) * (1 + 0.5)\",\n",
    "    \"((NIR - RED) / (NIR + RED))**(0.5)\",\n",
    "    \"(NIR - GREEN) / (NIR + GREEN)\",\n",
    "    \"(NIR - SWIR3) / (NIR + SWIR3)\",\n",
    "    \"(NIR / RED) - 1\",\n",
    "    \"(NIR / RED_EDGE1) - 1\",\n",
    "    \"(RED_EDGE1 - RED) / (RED_EDGE1 + RED)\",\n",
    "    \"(NIR - RED_EDGE1) / (NIR + RED_EDGE1)\",\n",
    "    \"(NIR - (2 * RED) + BLUE) / (NIR + (2 * RED) + BLUE)\",\n",
    "    \"(GREEN - RED) / (GREEN + RED - BLUE)\",\n",
    "    \"(BLUE+NIR)/(RED+SWIR3)\",\n",
    "    \"ULTRA_BLUE\",\n",
    "    \"BLUE\",\n",
    "    \"GREEN\",\n",
    "    \"RED\",\n",
    "    \"RED_EDGE1\",\n",
    "    \"RED_EDGE2\",\n",
    "    \"RED_EDGE3\",\n",
    "    \"NIR\",\n",
    "    \"N_NIR\",\n",
    "    \"WV\",\n",
    "    \"SWIR2\",\n",
    "    \"SWIR3\",\n",
    "]\n",
    "\n",
    "methods = [\"mean\", \"median\", \"harmonic\", \"geometric\", \"max\", \"min\", \"sum\"]\n",
    "russian_methods = [\"средняя\", \"медианная\", \"гармон.\", \"геометр.\", \"макс.\", \"мин.\", \"сумма\"]\n",
    "\n",
    "def substitute_values(input_string):\n",
    "    replacements = {\n",
    "        'ULTRA_BLUE': 'indices_df.iloc[sample][\"B01\"]',\n",
    "        'BLUE': 'indices_df.iloc[sample][\"B02\"]',\n",
    "        'GREEN': 'indices_df.iloc[sample][\"B03\"]',\n",
    "        'RED': 'indices_df.iloc[sample][\"B04\"]',\n",
    "        'RED_EDGE1': 'indices_df.iloc[sample][\"B05\"]',\n",
    "        'RED_EDGE2': 'indices_df.iloc[sample][\"B06\"]',\n",
    "        'RED_EDGE3': 'indices_df.iloc[sample][\"B07\"]',\n",
    "        'NIR': 'indices_df.iloc[sample][\"B08\"]',\n",
    "        'N_NIR': 'indices_df.iloc[sample][\"B8A\"]',\n",
    "        'WV': 'indices_df.iloc[sample][\"B09\"]',\n",
    "        'SWIR2': 'indices_df.iloc[sample][\"B11\"]',\n",
    "        'SWIR3': 'indices_df.iloc[sample][\"B12\"]',\n",
    "    }\n",
    "\n",
    "    # Use regular expressions to replace whole words only\n",
    "    for key, value in replacements.items():\n",
    "        pattern = r'\\b{}\\b'.format(re.escape(key))\n",
    "        input_string = re.sub(pattern, value, input_string)\n",
    "    \n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dfb22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_layer = dict()\n",
    "for index in indices:\n",
    "    outer_layer[index] = dict()\n",
    "    for method in methods:\n",
    "        outer_layer[index][method] = dict()\n",
    "        values = []\n",
    "        for sample in indices_df.index:\n",
    "            result = substitute_values(index).replace(\"sample\", str(sample))\n",
    "            if method == \"mean\":\n",
    "                value = eval(result).mean()\n",
    "            elif method == \"median\":\n",
    "                value = ma.median(eval(result))\n",
    "            elif method == \"harmonic\":\n",
    "                try:\n",
    "                    value = hmean(eval(result).reshape(eval(result).shape[1] * eval(result).shape[0]))\n",
    "                except ValueError:\n",
    "                    value = np.nan\n",
    "            elif method == \"geometric\":\n",
    "                try:\n",
    "                    value = gmean(eval(result).reshape(eval(result).shape[1] * eval(result).shape[0]))\n",
    "                except ValueError:\n",
    "                    value = np.nan\n",
    "            elif method == \"max\":\n",
    "                value = eval(result).max()\n",
    "            elif method == \"min\":\n",
    "                value = eval(result).min()\n",
    "            else:\n",
    "                value = eval(result).sum()\n",
    "            \n",
    "            values.append(value)\n",
    "        outer_layer[index][method] = np.corrcoef(values, list(indices_df[\"greenmass\"]))[0, 1]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(outer_layer).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8121271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(outer_layer).transpose().to_excel(\"ComparisoinTable.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53301dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77962d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer_layer = dict()\n",
    "\n",
    "# # Assuming you have 17 rows and 7 columns\n",
    "# total_rows = 25\n",
    "# total_columns = 7\n",
    "\n",
    "# # Calculate the height and width ratios for each subplot\n",
    "# height_ratios = np.ones(total_rows)\n",
    "# width_ratios = np.ones(total_columns)\n",
    "\n",
    "# fig, axs = plt.subplots(len(indices), len(methods), gridspec_kw={'height_ratios': height_ratios, 'width_ratios': width_ratios}, figsize=(60, 130))\n",
    "\n",
    "# for i, index in enumerate(indices):\n",
    "#     outer_layer[index] = dict()\n",
    "#     for m, method in enumerate(methods):\n",
    "#         outer_layer[index][method] = dict()\n",
    "#         values = []\n",
    "#         for sample in indices_df.index:\n",
    "#             result = substitute_values(index).replace(\"sample\", str(sample))\n",
    "#             if method == \"mean\":\n",
    "#                 value = eval(result).mean()\n",
    "#             elif method == \"median\":\n",
    "#                 value = ma.median(eval(result))\n",
    "#             elif method == \"harmonic\":\n",
    "#                 try:\n",
    "#                     value = hmean(eval(result).reshape(eval(result).shape[1] * eval(result).shape[0]))\n",
    "#                 except ValueError:\n",
    "#                     value = np.nan\n",
    "#             elif method == \"geometric\":\n",
    "#                 try:\n",
    "#                     value = gmean(eval(result).reshape(eval(result).shape[1] * eval(result).shape[0]))\n",
    "#                 except ValueError:\n",
    "#                     value = np.nan\n",
    "#             elif method == \"max\":\n",
    "#                 value = eval(result).max()\n",
    "#             elif method == \"min\":\n",
    "#                 value = eval(result).min()\n",
    "#             else:\n",
    "#                 value = eval(result).sum()\n",
    "            \n",
    "#             values.append(value)\n",
    "            \n",
    "#         # Assuming value_x and value_y are your new variable names\n",
    "#         value_x = np.array(values)\n",
    "#         value_y = indices_df[\"greenmass\"]\n",
    "#         try:\n",
    "#             # Assuming value_x and value_y are your new variable names\n",
    "#             coefficients = np.polyfit(value_x, value_y, 1)\n",
    "#             slope, intercept = coefficients\n",
    "#             regression_line = slope * value_x + intercept\n",
    "\n",
    "#             distances = np.abs(value_y - (slope * value_x + intercept)) / np.sqrt(slope**2 + 1)\n",
    "#             mean_distance = np.mean(distances)\n",
    "\n",
    "#             # Root Mean Squared Error (RMSE)\n",
    "#             rmse = np.sqrt(np.mean(distances**2))\n",
    "\n",
    "#             # R-squared (coefficient of determination)\n",
    "#             mean_y = np.mean(value_y)\n",
    "#             ss_total = np.sum((value_y - mean_y)**2)\n",
    "#             ss_residual = np.sum(distances**2)\n",
    "#             r_squared = 1 - (ss_residual / ss_total)\n",
    "\n",
    "#             axs[i, m].scatter(value_x, value_y, marker='o', linestyle='-', label=f'Коэффициент детерминации (R^2): {r_squared:.2f}\\nCреднеквадратичная ошибка (RMSE): {rmse:.2f}')\n",
    "#             if intercept > 0:\n",
    "#                 axs[i, m].plot(value_x, regression_line, color='red', label=f'Регрессионная прямая: $y = {slope:.2f}x +{intercept:.2f}$')\n",
    "#             else:\n",
    "#                 axs[i, m].plot(value_x, regression_line, color='red', label=f'Регрессионная прямая: $y = {slope:.2f}x {intercept:.2f}$')\n",
    "\n",
    "#             axs[i, m].set_xlabel('Значения индекса (канала)')\n",
    "#             axs[i, m].set_ylabel('Фактическая урожайность (т/га)')\n",
    "#             axs[i, m].set_title(f'Корреляция данных: {index} -> ({russian_methods[m]})')\n",
    "\n",
    "#             axs[i, m].legend()          \n",
    "#         except Exception as error:\n",
    "#             pass\n",
    "# #             print(f'Ошибка данных {index} + {method}')\n",
    "# #             print(error)\n",
    "            \n",
    "#         outer_layer[index][method] = np.corrcoef(values, list(indices_df[\"greenmass\"]))[0, 1]\n",
    "      \n",
    "# plt.tight_layout()\n",
    "# plt.show()            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
